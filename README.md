# Data Science Toolkit

Un framework modular y extensible para anÃ¡lisis de datos, machine learning y pipelines ETL.

## ğŸš€ CaracterÃ­sticas

- **Data Engineering**: Pipelines ETL automatizados y escalables
- **Data Analysis**: AnÃ¡lisis exploratorio automÃ¡tico y visualizaciones interactivas
- **Machine Learning**: Preprocesamiento, entrenamiento y evaluaciÃ³n de modelos
- **Modular**: Arquitectura flexible que permite usar solo lo que necesites
- **Extensible**: FÃ¡cil de extender con nuevos extractores, transformadores y modelos

## ğŸ“ Estructura del Proyecto

```
data-science-toolkit/
â”‚
â”œâ”€â”€ data/                          # Datos de ejemplo o tests
â”‚   â”œâ”€â”€ raw/                       # Datos sin procesar
â”‚   â”œâ”€â”€ processed/                 # Datos limpios/listos
â”‚   â””â”€â”€ external/                  # Fuentes externas (APIs, SQL dumps)
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter Notebooks para demos o pruebas
â”‚   â”œâ”€â”€ eda_examples.ipynb
â”‚   â”œâ”€â”€ ml_models_demo.ipynb
â”‚   â””â”€â”€ etl_pipeline_demo.ipynb
â”‚
â”œâ”€â”€ src/                           # CÃ³digo principal del framework
â”‚   â”œâ”€â”€ data_engineering/          # ETL, pipelines y automatizaciones
â”‚   â”œâ”€â”€ data_analysis/             # EDA y visualizaciÃ³n
â”‚   â”œâ”€â”€ machine_learning/          # Modelos y entrenamiento
â”‚   â””â”€â”€ utils/                     # Funciones auxiliares
â”‚
â”œâ”€â”€ tests/                         # Tests unitarios y de integraciÃ³n
â”œâ”€â”€ docs/                          # DocumentaciÃ³n del proyecto
â”œâ”€â”€ requirements.txt               # Dependencias del proyecto
â”œâ”€â”€ setup.py                       # Para empaquetar como librerÃ­a
â””â”€â”€ README.md                      # Esta guÃ­a
```

## ğŸ› ï¸ InstalaciÃ³n

### Requisitos

- Python 3.8+
- pip

### InstalaciÃ³n desde el cÃ³digo fuente

```bash
# Clonar el repositorio
git clone https://github.com/tu-usuario/data-science-toolkit.git
cd data-science-toolkit

# Crear entorno virtual (recomendado)
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate

# Instalar dependencias
pip install -r requirements.txt

# Instalar en modo desarrollo
pip install -e .
```

## ğŸ“– Uso RÃ¡pido

### AnÃ¡lisis Exploratorio de Datos

```python
from src.data_analysis.eda import EDA
from src.data_analysis.visualization import Visualization

# Crear instancia de EDA
eda = EDA()

# Analizar dataset
report = eda.analyze(dataframe)

# Generar visualizaciones
viz = Visualization()
viz.create_summary_plots(dataframe)
```

### Pipeline ETL

```python
from src.data_engineering.pipeline import ETLPipeline

# Configurar pipeline
pipeline = ETLPipeline(
    source="database",
    destination="data_warehouse"
)

# Ejecutar pipeline
pipeline.run()
```

### Machine Learning

```python
from src.machine_learning.models import MLModels
from src.machine_learning.preprocess import Preprocessor

# Preprocesar datos
preprocessor = Preprocessor()
X_processed = preprocessor.fit_transform(X)

# Entrenar modelo
model = MLModels()
model.train(X_processed, y)
```

## ğŸ§ª Testing

```bash
# Ejecutar todos los tests
pytest

# Con cobertura
pytest --cov=src

# Tests especÃ­ficos
pytest tests/test_eda.py
```

## ğŸ“š DocumentaciÃ³n

- [Arquitectura](docs/architecture.md) - DiseÃ±o del sistema
- [Ejemplos de Uso](docs/usage_examples.md) - GuÃ­as prÃ¡cticas
- [Roadmap](docs/roadmap.md) - Plan de desarrollo

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles.

## ğŸ—ºï¸ Roadmap

Ver [docs/roadmap.md](docs/roadmap.md) para el plan de desarrollo detallado.

## ğŸ“ Contacto

- Autor: Tu Nombre
- Email: tu.email@ejemplo.com
- Proyecto: [https://github.com/tu-usuario/data-science-toolkit](https://github.com/tu-usuario/data-science-toolkit)
